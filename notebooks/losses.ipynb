{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30147648-c918-4fbf-98d3-5379807d3e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/andrew/courses/MIPT_MLOps/mb_opc\n",
      "/Users/andrew/courses/MIPT_MLOps/mb_opc\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0b17b1f5-085e-45a8-b85e-1c9dda274430",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from src.dataset import OPCDataset, apply_transform\n",
    "from src.losses import BoundaryLoss, TVLoss, ContourLoss, IouLoss\n",
    "from src.metrics import PixelAccuracy, IoU\n",
    "from src.utils import set_random_seed, load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e40a9e28-79a9-4170-a2d6-d0e7d1129993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: mps\n"
     ]
    }
   ],
   "source": [
    "DATASET_PATH = 'data/processed/gds_dataset'\n",
    "BATCH_SIZE = 1\n",
    "MODEL_TYPE = 'manet'\n",
    "\n",
    "TEST_DATASET = OPCDataset(\n",
    "    os.path.join(DATASET_PATH, \"origin/test_origin/\"),\n",
    "    os.path.join(DATASET_PATH, \"correction/test_correction/\"),\n",
    "    transform=apply_transform(binarize_flag=True),\n",
    ")\n",
    "\n",
    "TEST_LOADER = DataLoader(\n",
    "    TEST_DATASET, batch_size=BATCH_SIZE, shuffle=True, num_workers=8\n",
    ")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available() and MODEL_TYPE not in [\"cfno\", \"pspnet\"]:\n",
    "    DEVICE = torch.device(\"mps\")\n",
    "else:\n",
    "    DEVICE = torch.device(\"cpu\")\n",
    "print(f\"Using: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba7f42dc-68a9-43b9-8d7b-a90116177b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights from local directory\n",
      "Model 'manet' loaded.\n",
      "Total parameters: 31777361\n"
     ]
    }
   ],
   "source": [
    "model = load_model(model_type = MODEL_TYPE, \n",
    "                   weights_path = 'checkpoints/manet_checkpoint', \n",
    "                   device = DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a316945-400b-4099-a23d-3fe3c953c1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "tv_loss = TVLoss(weight=1.0)\n",
    "contour_loss = ContourLoss(weight=1.0, device=DEVICE)\n",
    "mae_loss = torch.nn.L1Loss()\n",
    "iou_loss = IouLoss(weight=1.0)\n",
    "pixel_acc = PixelAccuracy()\n",
    "bce = torch.nn.BCELoss()\n",
    "boundary_loss = BoundaryLoss(device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8fb5cbc-d33c-4051-b19a-c97dee848d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: torch.Size([1, 1, 1024, 1024])\n",
      "Target shape: torch.Size([1, 1, 1024, 1024])\n"
     ]
    }
   ],
   "source": [
    "image, target = next(iter(TEST_LOADER))\n",
    "image, target = image.to(DEVICE), target.to(DEVICE)\n",
    "print(f'Image shape: {image.shape}')\n",
    "print(f'Target shape: {target.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "65e5505a-f7e0-43c5-a687-da5d6fd3c0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "  pred = model(image).sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2c0306a0-6a82-4f12-a210-3a7579c5d57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "contour_loss_iter = contour_loss(pred, target)\n",
    "mae_loss_iter = mae_loss(pred, target)\n",
    "iou_loss_iter = iou_loss(pred, target)\n",
    "bce_loss = bce(pred, target)\n",
    "bd_loss = boundary_loss(pred, target)\n",
    "total_loss = mae_loss_iter + contour_loss_iter + iou_loss_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "290c6056-2bfa-4b7e-a877-b625fe9915f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contour loss:0.106756791472435\n",
      "mse loss:0.0005883198464289308\n",
      "iou_loss:0.004180252552032471\n",
      "bce loss:0.002033837605267763\n",
      "Boundary loss:2.135075092315674\n"
     ]
    }
   ],
   "source": [
    "print(f'contour loss:{contour_loss_iter}')\n",
    "print(f'mse loss:{mae_loss_iter}')\n",
    "print(f'iou_loss:{iou_loss_iter}')\n",
    "print(f'bce loss:{bce_loss}')\n",
    "print(f'Boundary loss:{bd_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "01039790-fb96-4306-ba10-96ce98847df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pixel Accuracy: 0.9994430541992188\n",
      "IoU: 0.9958197474479675\n"
     ]
    }
   ],
   "source": [
    "pixel_acc = PixelAccuracy()\n",
    "iou = IoU()\n",
    "accuracy = pixel_acc(pred, target)\n",
    "\n",
    "print(f'Pixel Accuracy: {accuracy}')\n",
    "print(f'IoU: {iou(pred, target)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mbopc",
   "language": "python",
   "name": "mbopc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
